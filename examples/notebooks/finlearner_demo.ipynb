{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ“ˆ FinLearner - Complete Demo Notebook\n",
                "\n",
                "This notebook demonstrates all modules and functions in the **FinLearner** library.\n",
                "\n",
                "## Table of Contents\n",
                "1. [Data Loading](#1-data-loading)\n",
                "2. [Technical Indicators](#2-technical-indicators)\n",
                "3. [Deep Learning Models](#3-deep-learning-models)\n",
                "4. [Gradient Boosting](#4-gradient-boosting)\n",
                "5. [Anomaly Detection](#5-anomaly-detection)\n",
                "6. [Risk Metrics](#6-risk-metrics)\n",
                "7. [Portfolio Optimization](#7-portfolio-optimization)\n",
                "8. [Visualization](#8-visualization)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies if needed\n",
                "# !pip install finlearner yfinance tensorflow xgboost lightgbm plotly"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Suppress warnings for cleaner output\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import sys\n",
                "import io\n",
                "\n",
                "# Fix encoding for Windows terminals\n",
                "sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\n",
                "\n",
                "# Import all FinLearner modules\n",
                "from finlearner import (\n",
                "    # Data\n",
                "    DataLoader,\n",
                "    # Technical\n",
                "    TechnicalIndicators,\n",
                "    # Deep Learning\n",
                "    TimeSeriesPredictor,\n",
                "    GRUPredictor,\n",
                "    CNNLSTMPredictor,\n",
                "    TransformerPredictor,\n",
                "    EnsemblePredictor,\n",
                "    # Machine Learning\n",
                "    GradientBoostPredictor,\n",
                "    # Anomaly\n",
                "    VAEAnomalyDetector,\n",
                "    # Risk\n",
                "    RiskMetrics,\n",
                "    historical_var,\n",
                "    parametric_var,\n",
                "    monte_carlo_var,\n",
                "    cvar,\n",
                "    max_drawdown,\n",
                "    # Portfolio\n",
                "    PortfolioOptimizer,\n",
                "    BlackLittermanOptimizer,\n",
                "    RiskParityOptimizer,\n",
                "    # Visualization\n",
                "    Plotter\n",
                ")\n",
                "\n",
                "print('âœ… All modules imported successfully!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Data Loading\n",
                "\n",
                "The `DataLoader` class downloads historical stock data from Yahoo Finance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download stock data\n",
                "ticker = 'AAPL'\n",
                "df = DataLoader.download_data(ticker, start='2023-01-01', end='2024-01-01')\n",
                "\n",
                "print(f'Downloaded {len(df)} days of {ticker} data')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick price plot\n",
                "plt.figure(figsize=(12, 4))\n",
                "plt.plot(df['Close'], label=ticker)\n",
                "plt.title(f'{ticker} Closing Prices')\n",
                "plt.xlabel('Date')\n",
                "plt.ylabel('Price ($)')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Technical Indicators\n",
                "\n",
                "The `TechnicalIndicators` class adds various technical analysis indicators to the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add all technical indicators\n",
                "ti = TechnicalIndicators(df.copy())\n",
                "df_with_indicators = ti.add_all()\n",
                "\n",
                "print('Added indicators:', df_with_indicators.columns.tolist())\n",
                "df_with_indicators.tail()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot price with moving averages\n",
                "fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
                "\n",
                "# Price + MAs\n",
                "axes[0].plot(df_with_indicators['Close'], label='Close', alpha=0.8)\n",
                "# Note: Column names depend on indicator implementation (e.g., MA20 or SMA_20)\n",
                "# Checking typical names from library\n",
                "if 'MA20' in df_with_indicators.columns:\n",
                "    axes[0].plot(df_with_indicators['MA20'], label='SMA 20', linestyle='--')\n",
                "elif 'SMA_20' in df_with_indicators.columns:\n",
                "    axes[0].plot(df_with_indicators['SMA_20'], label='SMA 20', linestyle='--')\n",
                "    \n",
                "if 'EMA12' in df_with_indicators.columns:\n",
                "    axes[0].plot(df_with_indicators['EMA12'], label='EMA 12', linestyle='--')\n",
                "elif 'EMA_12' in df_with_indicators.columns:\n",
                "    axes[0].plot(df_with_indicators['EMA_12'], label='EMA 12', linestyle='--')\n",
                "\n",
                "axes[0].set_title('Price with Moving Averages')\n",
                "axes[0].legend()\n",
                "\n",
                "# RSI\n",
                "axes[1].plot(df_with_indicators['RSI'], label='RSI', color='purple')\n",
                "axes[1].axhline(70, color='red', linestyle='--', alpha=0.5)\n",
                "axes[1].axhline(30, color='green', linestyle='--', alpha=0.5)\n",
                "axes[1].set_title('RSI Indicator')\n",
                "axes[1].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Deep Learning Models\n",
                "\n",
                "FinLearner provides multiple deep learning architectures for time series prediction."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.1 LSTM Predictor (TimeSeriesPredictor)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LSTM Model\n",
                "lstm = TimeSeriesPredictor(lookback_days=30)\n",
                "lstm.fit(df, epochs=5)\n",
                "\n",
                "lstm_predictions = lstm.predict(df)\n",
                "print(f'LSTM predictions shape: {lstm_predictions.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 GRU Predictor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GRU Model\n",
                "gru = GRUPredictor(lookback_days=30, gru_units=(64, 32))\n",
                "gru.fit(df, epochs=5)\n",
                "\n",
                "gru_predictions = gru.predict(df)\n",
                "print(f'GRU predictions shape: {gru_predictions.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3 CNN-LSTM Hybrid"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CNN-LSTM Hybrid Model\n",
                "cnn_lstm = CNNLSTMPredictor(lookback_days=30, filters=32, kernel_size=3)\n",
                "cnn_lstm.fit(df, epochs=5)\n",
                "\n",
                "cnn_lstm_predictions = cnn_lstm.predict(df)\n",
                "print(f'CNN-LSTM predictions shape: {cnn_lstm_predictions.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.4 Transformer Predictor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Transformer Model with self-attention\n",
                "transformer = TransformerPredictor(lookback_days=30, num_heads=4, d_model=64)\n",
                "transformer.fit(df, epochs=5)\n",
                "\n",
                "transformer_predictions = transformer.predict(df)\n",
                "print(f'Transformer predictions shape: {transformer_predictions.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.5 Ensemble Predictor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ensemble: Weighted combination of LSTM + GRU + Attention\n",
                "ensemble = EnsemblePredictor(\n",
                "    lookback_days=30, \n",
                "    weights={'lstm': 0.4, 'gru': 0.3, 'attention': 0.3}\n",
                ")\n",
                "ensemble.fit(df, epochs=5)\n",
                "\n",
                "ensemble_predictions = ensemble.predict(df)\n",
                "print(f'Ensemble predictions shape: {ensemble_predictions.shape}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Formatting helper\n",
                "def fmt_mae(pred, actual):\n",
                "    # Align lengths by taking the last N points\n",
                "    p = pred[-len(actual):].flatten()\n",
                "    mae = np.mean(np.abs(p - actual))\n",
                "    return f'{mae:.2f}'\n",
                "\n",
                "# Compare all model predictions\n",
                "fig, ax = plt.subplots(figsize=(14, 6))\n",
                "\n",
                "# 1. Determine minimum length among all predictions\n",
                "min_len = min(len(lstm_predictions), len(gru_predictions), \n",
                "              len(cnn_lstm_predictions), len(transformer_predictions), \n",
                "              len(ensemble_predictions))\n",
                "\n",
                "# 2. Get actual prices aligned to that length\n",
                "actual = df['Close'].values[-min_len:]\n",
                "\n",
                "# 3. Print metrics\n",
                "print('\\nMean Absolute Error:')\n",
                "print(f'  LSTM:        {fmt_mae(lstm_predictions, actual)}')\n",
                "print(f'  GRU:         {fmt_mae(gru_predictions, actual)}')\n",
                "print(f'  CNN-LSTM:    {fmt_mae(cnn_lstm_predictions, actual)}')\n",
                "print(f'  Transformer: {fmt_mae(transformer_predictions, actual)}')\n",
                "print(f'  Ensemble:    {fmt_mae(ensemble_predictions, actual)}')\n",
                "\n",
                "# 4. Plot aligned predictions\n",
                "ax.plot(actual, label='Actual', linewidth=2, color='black')\n",
                "ax.plot(lstm_predictions[-len(actual):].flatten(), label='LSTM', alpha=0.7)\n",
                "ax.plot(gru_predictions[-len(actual):].flatten(), label='GRU', alpha=0.7)\n",
                "ax.plot(cnn_lstm_predictions[-len(actual):].flatten(), label='CNN-LSTM', alpha=0.7)\n",
                "ax.plot(transformer_predictions[-len(actual):].flatten(), label='Transformer', alpha=0.7)\n",
                "ax.plot(ensemble_predictions[-len(actual):].flatten(), label='Ensemble', alpha=0.7)\n",
                "\n",
                "ax.set_title('Deep Learning Model Comparison')\n",
                "ax.set_xlabel('Time')\n",
                "ax.set_ylabel('Price')\n",
                "ax.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Gradient Boosting\n",
                "\n",
                "The `GradientBoostPredictor` supports both XGBoost and LightGBM with automatic feature engineering."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# XGBoost Predictor\n",
                "xgb_predictor = GradientBoostPredictor(\n",
                "    backend='xgboost',\n",
                "    n_estimators=100,\n",
                "    max_depth=6,\n",
                "    learning_rate=0.1\n",
                ")\n",
                "\n",
                "xgb_predictor.fit(df)\n",
                "xgb_predictions = xgb_predictor.predict(df)\n",
                "\n",
                "print(f'XGBoost predictions shape: {xgb_predictions.shape}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature importance\n",
                "importance = xgb_predictor.feature_importance()\n",
                "\n",
                "# Plot top 10 features\n",
                "top_10 = importance.head(10)\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.barh(top_10['feature'], top_10['importance'], color='steelblue')\n",
                "plt.xlabel('Importance')\n",
                "plt.title('Top 10 Feature Importances (XGBoost)')\n",
                "plt.gca().invert_yaxis()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LightGBM Predictor\n",
                "lgb_predictor = GradientBoostPredictor(\n",
                "    backend='lightgbm',\n",
                "    n_estimators=100,\n",
                "    max_depth=6\n",
                ")\n",
                "\n",
                "lgb_predictor.fit(df)\n",
                "lgb_predictions = lgb_predictor.predict(df)\n",
                "\n",
                "print(f'LightGBM predictions shape: {lgb_predictions.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Anomaly Detection\n",
                "\n",
                "The `VAEAnomalyDetector` uses a Variational Autoencoder to identify unusual price patterns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# VAE Anomaly Detector\n",
                "vae = VAEAnomalyDetector(\n",
                "    lookback_days=20,\n",
                "    latent_dim=8,\n",
                "    hidden_dims=(64, 32)\n",
                ")\n",
                "\n",
                "vae.fit(df, epochs=20, batch_size=16)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Detect anomalies\n",
                "anomaly_scores = vae.detect_anomalies(df)\n",
                "anomaly_df = vae.get_anomalies(df, percentile=95)\n",
                "\n",
                "print(f'Total anomalies detected: {anomaly_df[\"Is_Anomaly\"].sum()}')\n",
                "anomaly_df[anomaly_df['Is_Anomaly']].head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot anomalies\n",
                "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
                "\n",
                "# Price with anomaly markers\n",
                "axes[0].plot(anomaly_df['Close'], label='Price', color='steelblue')\n",
                "anomalies = anomaly_df[anomaly_df['Is_Anomaly']]\n",
                "axes[0].scatter(anomalies.index, anomalies['Close'], color='red', s=50, label='Anomaly', zorder=5)\n",
                "axes[0].set_title('Price with Detected Anomalies')\n",
                "axes[0].legend()\n",
                "\n",
                "# Anomaly scores\n",
                "axes[1].plot(anomaly_df.index, anomaly_df['Anomaly_Score'], color='orange')\n",
                "axes[1].axhline(vae.reconstruction_threshold, color='red', linestyle='--', label='Threshold')\n",
                "axes[1].set_title('Anomaly Scores')\n",
                "axes[1].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get latent space representation\n",
                "latent = vae.get_latent_representation(df)\n",
                "print(f'Latent representation shape: {latent.shape}')\n",
                "\n",
                "# Visualize first 2 dimensions\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.scatter(latent[:, 0], latent[:, 1], c=range(len(latent)), cmap='viridis', alpha=0.6)\n",
                "plt.colorbar(label='Time Index')\n",
                "plt.xlabel('Latent Dim 1')\n",
                "plt.ylabel('Latent Dim 2')\n",
                "plt.title('VAE Latent Space Representation')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Risk Metrics\n",
                "\n",
                "The `RiskMetrics` class provides comprehensive risk analysis including VaR, CVaR, and drawdown metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create RiskMetrics from prices\n",
                "risk = RiskMetrics.from_prices(df['Close'])\n",
                "\n",
                "# Get risk summary\n",
                "summary = risk.summary(confidence=0.95)\n",
                "print('\\nðŸ“Š Risk Summary (95% confidence):')\n",
                "summary"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.1 Value at Risk (VaR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Different VaR calculation methods\n",
                "returns = df['Close'].pct_change().dropna()\n",
                "\n",
                "var_historical = risk.historical_var(confidence=0.95)\n",
                "var_parametric = risk.parametric_var(confidence=0.95)\n",
                "var_monte_carlo = risk.monte_carlo_var(confidence=0.95, simulations=10000)\n",
                "var_cornish_fisher = risk.cornish_fisher_var(confidence=0.95)\n",
                "\n",
                "print('Value at Risk (95% confidence):')\n",
                "print(f'  Historical:     {var_historical:.4f} ({var_historical*100:.2f}%)')\n",
                "print(f'  Parametric:     {var_parametric:.4f} ({var_parametric*100:.2f}%)')\n",
                "print(f'  Monte Carlo:    {var_monte_carlo:.4f} ({var_monte_carlo*100:.2f}%)')\n",
                "print(f'  Cornish-Fisher: {var_cornish_fisher:.4f} ({var_cornish_fisher*100:.2f}%)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Standalone VaR functions\n",
                "print('\\nUsing standalone functions:')\n",
                "print(f'  historical_var: {historical_var(returns, 0.95):.4f}')\n",
                "print(f'  parametric_var: {parametric_var(returns, 0.95):.4f}')\n",
                "print(f'  monte_carlo_var: {monte_carlo_var(returns, 0.95, simulations=10000):.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.2 Conditional VaR (CVaR / Expected Shortfall)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CVaR - Expected loss beyond VaR\n",
                "cvar_hist = risk.cvar(confidence=0.95, method='historical')\n",
                "cvar_param = risk.cvar(confidence=0.95, method='parametric')\n",
                "\n",
                "print('Conditional VaR (95% confidence):')\n",
                "print(f'  Historical CVaR: {cvar_hist:.4f} ({cvar_hist*100:.2f}%)')\n",
                "print(f'  Parametric CVaR: {cvar_param:.4f} ({cvar_param*100:.2f}%)')\n",
                "print(f'\\nNote: CVaR > VaR because it measures tail risk beyond VaR')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.3 Maximum Drawdown"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Maximum Drawdown analysis\n",
                "max_dd = risk.max_drawdown()\n",
                "dd_series = risk.max_drawdown(as_series=True)\n",
                "calmar = risk.calmar_ratio()\n",
                "\n",
                "print('Drawdown Metrics:')\n",
                "print(f'  Max Drawdown: {max_dd:.4f} ({max_dd*100:.2f}%)')\n",
                "print(f'  Calmar Ratio: {calmar:.4f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize drawdown over time\n",
                "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
                "\n",
                "# Cumulative returns\n",
                "cumulative = (1 + returns).cumprod()\n",
                "axes[0].plot(cumulative, color='steelblue')\n",
                "axes[0].set_title('Cumulative Returns')\n",
                "axes[0].set_ylabel('Growth Factor')\n",
                "\n",
                "# Drawdown\n",
                "axes[1].fill_between(dd_series.index, dd_series.values, 0, color='red', alpha=0.3)\n",
                "axes[1].plot(dd_series, color='red')\n",
                "axes[1].set_title('Drawdown Over Time')\n",
                "axes[1].set_ylabel('Drawdown')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. Portfolio Optimization\n",
                "\n",
                "FinLearner provides three portfolio optimization strategies."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.1 Markowitz Mean-Variance Optimization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Portfolio of tech stocks\n",
                "tickers = ['AAPL', 'GOOG', 'MSFT', 'AMZN', 'META']\n",
                "\n",
                "# Markowitz Optimizer\n",
                "markowitz = PortfolioOptimizer(\n",
                "    tickers=tickers,\n",
                "    start='2023-01-01',\n",
                "    end='2024-01-01'\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Optimize portfolio\n",
                "results, allocations, metrics = markowitz.optimize(num_portfolios=1000)\n",
                "\n",
                "print('ðŸ“Š Markowitz Optimal Portfolio:')\n",
                "print(allocations)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Efficient Frontier\n",
                "markowitz.plot_efficient_frontier()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.2 Black-Litterman Optimization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Black-Litterman with investor views\n",
                "bl_optimizer = BlackLittermanOptimizer(\n",
                "    tickers=tickers,\n",
                "    start='2023-01-01',\n",
                "    end='2024-01-01'\n",
                ")\n",
                "\n",
                "# Define views: AAPL will return 20%, MSFT 15%\n",
                "views = {\n",
                "    'AAPL': 0.20,\n",
                "    'MSFT': 0.15\n",
                "}\n",
                "\n",
                "bl_allocation, bl_metrics = bl_optimizer.optimize(views=views)\n",
                "\n",
                "print('ðŸ“Š Black-Litterman Optimal Portfolio:')\n",
                "print(bl_allocation)\n",
                "print(f'\\nExpected Return: {bl_metrics[\"expected_return\"]:.2%}')\n",
                "print(f'Volatility: {bl_metrics[\"volatility\"]:.2%}')\n",
                "print(f'Sharpe Ratio: {bl_metrics[\"sharpe_ratio\"]:.2f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.3 Risk Parity Optimization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Risk Parity - Equal risk contribution\n",
                "rp_optimizer = RiskParityOptimizer(\n",
                "    tickers=tickers,\n",
                "    start='2023-01-01',\n",
                "    end='2024-01-01'\n",
                ")\n",
                "\n",
                "rp_allocation, rp_metrics = rp_optimizer.optimize()\n",
                "\n",
                "print('ðŸ“Š Risk Parity Portfolio:')\n",
                "print(rp_allocation)\n",
                "print('\\nðŸ“ˆ Metrics:')\n",
                "print(rp_metrics)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare allocation strategies\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "# Markowitz\n",
                "axes[0].pie(allocations['allocation'], labels=allocations.index, autopct='%1.1f%%')\n",
                "axes[0].set_title('Markowitz')\n",
                "\n",
                "# Black-Litterman\n",
                "axes[1].pie(bl_allocation['Weight'], labels=bl_allocation.index, autopct='%1.1f%%')\n",
                "axes[1].set_title('Black-Litterman')\n",
                "\n",
                "# Risk Parity\n",
                "axes[2].pie(rp_allocation['Weight'], labels=rp_allocation.index, autopct='%1.1f%%')\n",
                "axes[2].set_title('Risk Parity')\n",
                "\n",
                "plt.suptitle('Portfolio Allocation Comparison', fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 8. Visualization\n",
                "\n",
                "The `Plotter` class provides interactive candlestick charts with indicators."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Interactive candlestick chart\n",
                "fig = Plotter.candlestick(df, title=f'{ticker} Candlestick Chart')\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Candlestick with volume\n",
                "fig = Plotter.candlestick(df_with_indicators, title=f'{ticker} with Volume', show_volume=True)\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸ“š Summary\n",
                "\n",
                "This notebook demonstrated all major features of FinLearner:\n",
                "\n",
                "| Module | Features |\n",
                "|--------|----------|\n",
                "| **Data** | `DataLoader.download_data()` |\n",
                "| **Technical** | `TechnicalIndicators.add_all()` - RSI, MACD, Bollinger, etc. |\n",
                "| **Deep Learning** | LSTM, GRU, CNN-LSTM, Transformer, Ensemble |\n",
                "| **ML** | XGBoost, LightGBM with feature engineering |\n",
                "| **Anomaly** | VAE-based anomaly detection |\n",
                "| **Risk** | VaR (4 methods), CVaR, Max Drawdown, Calmar |\n",
                "| **Portfolio** | Markowitz, Black-Litterman, Risk Parity |\n",
                "| **Visualization** | Interactive Plotly charts |"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}